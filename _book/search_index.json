[["introduction-to-statistics.html", "7 Introduction to statistics 7.1 Inferential statistics 7.2 Measures of central tendency 7.3 Measures of spread", " 7 Introduction to statistics In this chapter, we will learn about how to use statistics to analyze data. 7.1 Inferential statistics Inferential statistics is all about using a sample to make inferences about the population from which the sample was drawn. For example, we might want to check if the efficacy of the Pfizer vaccine is better than that of the Moderna vaccine for preventing COVID-19 (spoiler alert: it’s not!). Figure 7.1: A visualization of inferential statistics. Sampling bias and sampling error In inferential statistics, there are two main types of errors: sampling bias and sampling error. Both describe how there are differences between the sample and the population. Sampling bias: your sample may not be representative of the population. Sampling error: the difference between a sample and population value (e.g., you measure the heights of a sample to be 160 cm when the population height is in fact 155 cm). 7.2 Measures of central tendency Measures of central tendency. The three measures of central tendency are your mean, median, and mode. Mean: the arithmetic average. Median: a value that splits ordered data into two equal halves. Mode: the most frequent value in a dataset. Figure 7.2: A visualization of measures of central tendency. Figure retrieved from this Medium Digest article. 7.3 Measures of spread The main measures of spread are range, interquartile range, standard deviation, and variance. As you may already know, the range is the difference between the largest and smallest values in a dataset. Interquartile range. the difference between the third and first quartiles in a dataset (IQR = Q3 - Q1). IQR also represents the middle 50% of your dataset. Figure 7.3: How to compute interquartile range. Figure retrieved from Boston University statistics notes. We often visualize our data with a boxplot, which relies on the concept of quartiles and IQR. Figure 7.4: A boxplot to represent data. Figure adapted from Naysan Saran’s article. Exercise Given the following numbers, compute the interquartile range: 45, 47, 52, 52, 53, 55, 56, 58, 62, 80. Figure 7.5: A boxplot to represent data. Figure adapted from BYJU’s article. Standard deviation and variance. Both standard deviation (SD) and variance (Var) measure the spread of individual data points from the mean. A bigger SD or Var means a bigger spread. A smaller SD or Var means a smaller spread. The mathematical definition of population SD (\\(\\sigma\\)) and sample SD (\\(s\\)) is: \\[\\begin{align} \\sigma &amp;= \\sqrt{\\frac{\\sum_{i=1}^n (x_i - \\mu)^2}{n}} \\\\ s &amp;= \\sqrt{\\frac{\\sum_{i=1}^n (x_i - \\bar{x})^2}{n-1}} \\end{align}\\] The mathematical definition of population variance (\\(\\sigma^2\\)) and sample variance (\\(s^2\\)) is: \\[\\begin{align} \\sigma^2 &amp;= \\frac{\\sum_{i=1}^n (x_i - \\mu)^2}{n} \\\\ s^2 &amp;= \\frac{\\sum_{i=1}^n (x_i - \\bar{x})^2}{n-1} \\end{align}\\] Remarks: \\(x_i\\): individual data points. \\(\\mu\\): population mean. \\(\\bar{x}\\): sample mean. \\(n\\): number of datum in your dataset. We divide by \\(n-1\\) for sample standard deviation because to account for the greater variation of sample data as opposed to population data. Exercise Given the following 7 numbers, compute the standard deviation: 9, 4, 5, 4, 12, 7, 8. \\[\\begin{align*} \\mu &amp;= \\frac{9 + 4 + 5 + 4 + 12 + 7 + 8}{7} = 7 \\\\ \\sigma &amp;= \\sqrt{\\frac{\\sum (x_i - \\mu)^2}{n}} \\\\ &amp;= \\sqrt{ \\frac{ (9-7)^2 + (4-7)^2 + \\cdots }{7} } \\\\ &amp;\\approx 2.73 \\end{align*}\\] The final measure of spread we will cover is something called standard error. Standard error. Standard error (SE or SEM) measures the amount of spread of sample means from their true population mean. \\[\\begin{equation} SE = \\frac{\\sigma}{\\sqrt{n}} \\end{equation}\\] We will use SE extensively when we cover statistical tests. Here is an excellent article on the different use cases between SD and SEM. "]]
